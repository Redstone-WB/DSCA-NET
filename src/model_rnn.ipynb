{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "- Reference codes : Deep Learning for Healthcare, CS598, UIUC, Spring2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "\n",
    "# set seed\n",
    "seed = 100\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# Define data path\n",
    "DATA_PATH = \"./preprocessed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = pickle.load(open(os.path.join(DATA_PATH,'pid.pkl'), 'rb'))\n",
    "x_dem = pickle.load(open(os.path.join(DATA_PATH,'x_dem.pkl'), 'rb'))\n",
    "x_per = pickle.load(open(os.path.join(DATA_PATH,'x_per_added.pkl'), 'rb'))\n",
    "x_d = pickle.load(open(os.path.join(DATA_PATH,'x_d_added.pkl'), 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46520\n",
      "46520\n",
      "46520\n",
      "46520\n"
     ]
    }
   ],
   "source": [
    "print(len(pids))\n",
    "print(len(x_dem))\n",
    "print(len(x_per))\n",
    "print(len(x_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 249\n",
      "DemoGraphic: [0, 1, 1, 3, 0]\n",
      "Examination of first visit: [9.8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Prescription of first visit: [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Patient ID:\", pids[0])\n",
    "print(\"DemoGraphic:\", x_dem[0])\n",
    "print(\"Examination of first visit:\", x_per[0][0])\n",
    "print(\"Prescription of first visit:\", x_d[0][0])\n",
    "\n",
    "\n",
    "# for visit in range(len(vids[3])):\n",
    "#     print(f\"\\t{visit}-th visit id:\", vids[3][visit])\n",
    "#     print(f\"\\t{visit}-th visit diagnosis labels:\", seqs[3][visit])\n",
    "#     print(f\"\\t{visit}-th visit diagnosis codes:\", [rtypes[label] for label in seqs[3][visit]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Leaving Only patients who have both of examination and prescriptions\n",
    "dem_no_idx = set()\n",
    "per_no_idx = set()\n",
    "d_no_idx = set()\n",
    "\n",
    "for idx in range(len(x_dem)):\n",
    "    \n",
    "    if len(x_dem[idx]) == 0:\n",
    "        dem_no_idx.add(idx)\n",
    "    \n",
    "    if len(x_per[idx]) == 0:\n",
    "        per_no_idx.add(idx)\n",
    "    \n",
    "    if len(x_d[idx]) == 0:\n",
    "        d_no_idx.add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_no_idx = per_no_idx | d_no_idx\n",
    "all_idx = set(range(len(x_dem)))\n",
    "alive_idx = all_idx - tot_no_idx\n",
    "\n",
    "alive_idx_list = list(alive_idx)\n",
    "alive_idx_list.sort()\n",
    "\n",
    "\n",
    "x_dem_f = [x_dem[i] for i in alive_idx_list]\n",
    "x_per_f = [x_per[i] for i in alive_idx_list]\n",
    "x_d_f = [x_d[i] for i in alive_idx_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19432\n",
      "19432\n",
      "19432\n"
     ]
    }
   ],
   "source": [
    "print(len(x_dem_f))\n",
    "print(len(x_per_f))\n",
    "print(len(x_d_f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x_dem, x_per, x_d):\n",
    "        \n",
    "        self.x_dem = x_dem\n",
    "        self.x_per = x_per\n",
    "        self.x_d = x_d\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.x_d)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        x_dem = self.x_dem[index]\n",
    "        x_per = self.x_per[index]\n",
    "        x_d = self.x_d[index]\n",
    "        return x_dem, x_per, x_d\n",
    "        \n",
    "\n",
    "dataset = CustomDataset(x_dem_f, x_per_f, x_d_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "num_patients = len(x_per_f) # 11619\n",
    "num_visits = [len(patient) for patient in x_per_f] #\n",
    "max_num_visits = max(num_visits)\n",
    "\n",
    "num_codes = len(x_d_f[0][0])\n",
    "num_per_codes = len(x_per_f[0][0])\n",
    "print(max_num_visits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. (x_d) For all patients, Number of Visit (len(x_d)) must be same -> Need to be padded\n",
    "## 2. (x_d) For all patients, Number of Prescription codes must be same -> Already Done\n",
    "## 3. (x_per) For all patients, Number of Visit (len(x_per)) must be same -> Need to be padded\n",
    "## 4. Mask -> 0 For padded intputs -> No Need\n",
    "\n",
    "# def collate_fn(data):\n",
    "\n",
    "#     x_dem_now, x_per_now, x_d_now = zip(*data)\n",
    "\n",
    "#     x_dem_now = torch.tensor(x_dem_now[0], dtype=torch.float32)\n",
    "#     x_per_now = x_per_now[0]\n",
    "#     x_d_now = x_d_now[0]\n",
    "\n",
    "#     # print(len(x_per_now))\n",
    "#     # print(len(x_d_now))\n",
    "\n",
    "\n",
    "#     # x_d_new = torch.zeros((1, max_num_visits, num_codes), dtype=torch.long)\n",
    "#     # x_per_new = torch.zeros((1, max_num_visits, num_per_codes), dtype=torch.long)\n",
    "\n",
    "\n",
    "#     ## (x_d) \n",
    "#     length_valid_visit = len(x_d_now)\n",
    "#     # print(\"Valid Visit : {0}\".format(length_valid_visit))\n",
    "#     num_pad_visit = max_num_visits - length_valid_visit\n",
    "#     pad = [0] * num_codes  # [0, ... , 0] : For 400 zeros\n",
    "#     tmp = x_d_now.copy()\n",
    "#     tmp.extend([pad] * num_pad_visit)\n",
    "#     x_d_now = torch.tensor(tmp.copy(), dtype=torch.float32)\n",
    "\n",
    "#     # (x_per)\n",
    "#     length_valid = len(x_per_now)\n",
    "#     num_pad_visit = max_num_visits - length_valid\n",
    "#     pad = [0] * num_per_codes\n",
    "#     tmp2 = x_per_now.copy()\n",
    "#     tmp2.extend([pad] * num_pad_visit)\n",
    "#     x_per_now = torch.tensor(tmp2.copy(), dtype=torch.float32)\n",
    "    \n",
    "#     return x_dem_now, x_per_now, x_d_now\n",
    "\n",
    "\n",
    "## No collating\n",
    "def collate_fn(data):\n",
    "\n",
    "    x_dem_now, x_per_now, x_d_now = zip(*data)\n",
    "\n",
    "    x_dem_now = torch.tensor(x_dem_now[0], dtype=torch.float32)\n",
    "    x_per_now = torch.tensor(x_per_now[0], dtype=torch.float32)\n",
    "    x_d_now = torch.tensor(x_d_now[0], dtype=torch.float32)\n",
    "\n",
    "\n",
    "    \n",
    "    return x_dem_now, x_per_now, x_d_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=1, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x_dem_new, x_per_new, x_d_new = next(loader_iter)\n",
    "# print(x[0])\n",
    "# print(x_d_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([11, 19])\n",
      "torch.Size([11, 400])\n"
     ]
    }
   ],
   "source": [
    "# x_per, x_d : num patients, max num visits, num codes\n",
    "# x_dem : num_patients, num demo codes\n",
    "\n",
    "print(x_dem_new.size())\n",
    "print(x_per_new.size())  \n",
    "print(x_d_new.size())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 17488\n",
      "Length of val dataset: 1944\n"
     ]
    }
   ],
   "source": [
    "split = int(len(dataset)*0.9)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    \n",
    "    batch_size = 1\n",
    "    train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = load_data(train_dataset, val_dataset, collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17488\n",
      "1944\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader)) ## divided by 32, no remainder\n",
    "print(len(val_loader)) ## remainder exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([32, 19])\n",
      "torch.Size([32, 400])\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in train_loader:\n",
    "    print(a.size())\n",
    "    print(b.size())\n",
    "    print(c.size())\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "### RNN architecture\n",
    "### W_hh, W_ih, W_ho\n",
    "### Two Rnns, one for x_c, one for x_d\n",
    "### Combine Two Rnns\n",
    "class TwoRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, num_codes_d):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_hidden_dim = 128\n",
    "        self.num_codes_d = num_codes_d\n",
    "\n",
    "\n",
    "        ## W_ih\n",
    "        self.embedding = nn.Linear(num_codes + 5, self.num_hidden_dim)\n",
    "        self.embedding_d = nn.Linear(self.num_codes_d, self.num_hidden_dim)\n",
    "\n",
    "        # W_hh\n",
    "        self.linear_general = nn.Linear(self.num_hidden_dim * 2, self.num_hidden_dim)\n",
    "\n",
    "        # W_ho\n",
    "        self.linear_fin = nn.Linear(self.num_hidden_dim *2, self.num_codes_d)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, x_dem_new, x_per_new, x_d_new):\n",
    "        \n",
    "        # batch_size = x_d_new.shape[0] # batch_size = 1\n",
    "        x_dem_new = x_dem_new.squeeze(0) # num_demos\n",
    "        x_per_new = x_per_new.squeeze(0) # num_visit, num_examinations\n",
    "        x_d_new = x_d_new.squeeze(0) #num_visit, num_codes\n",
    "\n",
    "        if len(x_per_new.size()) == 1:\n",
    "            x_per_new = x_per_new.unsqueeze(0)\n",
    "            x_d_new = x_d_new.unsqueeze(0)\n",
    "\n",
    "        num_visits = x_per_new.size()[0]\n",
    "\n",
    "        for v_idx in range(num_visits):\n",
    "            if v_idx == 0:\n",
    "                h_t_minus_1_c = nn.init.kaiming_uniform_(torch.empty(1, self.num_hidden_dim)).squeeze(0)\n",
    "                h_t_minus_1_d = nn.init.kaiming_uniform_(torch.empty(1, self.num_hidden_dim)).squeeze(0)\n",
    "\n",
    "\n",
    "                # W_ih\n",
    "\n",
    "                x_c = self.embedding(torch.concat([x_dem_new, x_per_new[v_idx]], dim=0))\n",
    "                x_d = self.embedding_d(x_d_new[v_idx])\n",
    "\n",
    "                # W_hh\n",
    "                h_t_c = self.linear_general(torch.concat([x_c,h_t_minus_1_c]))\n",
    "                h_t_d = self.linear_general(torch.concat([x_d,h_t_minus_1_d]))\n",
    "\n",
    "\n",
    "                # W_ho\n",
    "                y_t_hat = self.linear_fin(torch.concat([h_t_c, h_t_d]))\n",
    "                y_t_hat = self.sigmoid(y_t_hat)\n",
    "                \n",
    "                # y_hats = y_t_hat.clone().detach().unsqueeze(0)\n",
    "                y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            else:\n",
    "                # W_ih\n",
    "                x_c = self.embedding(torch.concat([x_dem_new, x_per_new[v_idx]], dim=0))\n",
    "                x_d = self.embedding_d(x_d_new[v_idx])\n",
    "\n",
    "                # W_hh\n",
    "                h_t_c = self.linear_general(torch.concat([x_c,h_t_c]))\n",
    "                h_t_d = self.linear_general(torch.concat([x_d,h_t_d]))\n",
    "\n",
    "\n",
    "                # W_ho\n",
    "                y_t_hat = self.linear_fin(torch.concat([h_t_c, h_t_d]))\n",
    "                y_t_hat = self.sigmoid(y_t_hat)\n",
    "\n",
    "                y_hats = torch.concat([y_hats, y_t_hat.unsqueeze(0)], dim=0)\n",
    "\n",
    "\n",
    "        return y_hats\n",
    "    \n",
    "\n",
    "# load the model here\n",
    "twornn = TwoRNN(num_codes = num_per_codes, num_codes_d=num_codes)\n",
    "y_hats = twornn.forward(x_dem_new, x_per_new, x_d_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoRNN(\n",
       "  (embedding): Linear(in_features=24, out_features=128, bias=True)\n",
       "  (embedding_d): Linear(in_features=400, out_features=128, bias=True)\n",
       "  (linear_general): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear_fin): Linear(in_features=256, out_features=400, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twornn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(list(twornn.parameters()), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    \n",
    "    for idx, (x_dem_new, x_per_new, x_d_new) in enumerate(val_loader):\n",
    "        y_hat = model.forward(x_dem_new, x_per_new, x_d_new)\n",
    "        y_hat = (y_hat > 0.5).int()\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, x_d_new.detach().to('cpu')), dim=0)\n",
    "\n",
    "        if idx == 100:\n",
    "            break\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "        Calculate precision, recall, f1, and roc auc scores.\n",
    "        Use `average='binary'` for calculating precision, recall, and fscore.\n",
    "    \"\"\"\n",
    "    p, r, f, roc_auc = None, None, None, None\n",
    "    # print(y_pred.size()) ## batch_size *76, 400\n",
    "    # print(y_true.size()) ## batch_size *76, 400\n",
    "\n",
    "    # Micro F1\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    return p, r, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for idx, (x_dem_new, x_per_new, x_d_new) in enumerate(train_loader):\n",
    "            \"\"\"\n",
    "            TODO:\n",
    "                1. zero grad\n",
    "                2. model forward\n",
    "                3. calculate loss\n",
    "                4. loss backward\n",
    "                5. optimizer step\n",
    "            \"\"\"\n",
    "            loss = None\n",
    "            # your code here\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            ## model forward\n",
    "            y_hat = model.forward(x_dem_new, x_per_new, x_d_new)\n",
    "            \n",
    "            ##loss\n",
    "            # print(y_hat.size())\n",
    "            # print(x_d_new.size())\n",
    "\n",
    "            if len(x_d_new.size()) == 1:\n",
    "                x_d_new = x_d_new.unsqueeze(0)\n",
    "                loss = criterion(y_hat, x_d_new)\n",
    "            else:\n",
    "                loss = criterion(y_hat, x_d_new).sum()\n",
    "            \n",
    "            # print(loss.size()) (76,400) -> 1\n",
    "            # print(loss)\n",
    "            loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            # if idx % 100 == 0:\n",
    "            #     print(idx)\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f = eval_model(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}'\n",
    "              .format(epoch+1, p, r, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 2531.946257\n",
      "Epoch: 1 \t Validation p: 0.03, r:0.49, f: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \t Training Loss: 2531.943470\n",
      "Epoch: 2 \t Validation p: 0.03, r:0.49, f: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \t Training Loss: 2531.880741\n",
      "Epoch: 3 \t Validation p: 0.03, r:0.49, f: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \t Training Loss: 2531.922828\n",
      "Epoch: 4 \t Validation p: 0.03, r:0.49, f: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \t Training Loss: 2531.882389\n",
      "Epoch: 5 \t Validation p: 0.03, r:0.49, f: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \t Training Loss: 2531.919839\n",
      "Epoch: 6 \t Validation p: 0.03, r:0.49, f: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \t Training Loss: 2531.892286\n",
      "Epoch: 7 \t Validation p: 0.03, r:0.49, f: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \t Training Loss: 2531.905738\n",
      "Epoch: 8 \t Validation p: 0.03, r:0.49, f: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/618989496.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtwornn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwoRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_per_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_codes_d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwornn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/2446946331.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, n_epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "# about 1 hour, for 1 epoch\n",
    "n_epochs = 10\n",
    "twornn = TwoRNN(num_codes = num_per_codes, num_codes_d=num_codes)\n",
    "train(twornn, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0412082789483498\n",
      "0.5444307584022523\n",
      "0.07661734662291834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_66343/643064540.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "p,r,f = eval_model(twornn, val_loader)\n",
    "print(p)\n",
    "print(r)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/c4nc3b111l56r38yfxstwq740000gq/T/ipykernel_45854/1997501210.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hats = torch.tensor(y_t_hat, dtype=torch.float32).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "y_hats = dsca_net.forward(x_dem_new, x_per_new, x_d_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
